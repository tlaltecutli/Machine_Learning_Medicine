{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1. Cluster and Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;[1.1. Hierarchical Clustering and K-Means Clustering to Identify Subgroups in Surveys](#1.1.-Hierarchical-Clustering-and-K-Means-Clustering-to-Identify-Subgroups-in-Surveys)\\\n",
    "&emsp;[1.2. K-Means Clustering](#1.2.-K-Means-Clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information taken from [Machine Learning Google](https://refer.is/ahoje1bi)\n",
    "\n",
    "**What is clustering?** \n",
    "\n",
    "Suppose you are working with a dataset that includes patient information from a healthcare system. The dataset is complex and includes both categorical and numeric features. You want to find patterns and similarities in the dataset. How might you approach this task?\n",
    "\n",
    "Clustering is an unsupervised machine learning technique designed to group unlabeled examples based on their similarity to each other. (If the examples are labeled, this kind of grouping is called classification.) Consider a hypothetical patient study designed to evaluate a new treatment protocol. During the study, patients report how many times per week they experience symptoms and the severity of the symptoms. Researchers can use clustering analysis to group patients with similar treatment responses into clusters. Figure 1 demonstrates one possible grouping of simulated data into three clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\">\n",
    "  <img src = \"Images/clustering_example.png\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the unlabeled data on the left of Figure 1, you could guess that the data forms three clusters, even without a formal definition of similarity between data points. In real-world applications, however, you need to explicitly define a similarity measure, or the metric used to compare samples, in terms of the dataset's features. When examples have only a couple of features, visualizing and measuring similarity is straightforward. But as the number of features increases, combining and comparing features becomes less intuitive and more complex. Different similarity measures may be more or less appropriate for different clustering scenarios, and this course will address choosing an appropriate similarity measure in later sections: Manual similarity measures and Similarity measure from embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Clustering algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning datasets can have millions of examples, but not all clustering algorithms scale efficiently. Many clustering algorithms compute the similarity between all pairs of examples, which means their runtime increases as the square of the number of examples, denoted as $O(n^2)$ in complexity notation. $O(n^2)$ algorithms are not practical for datasets with millions of examples.\n",
    "\n",
    "The k-means algorithm has a complexity of $O(n)$, meaning that the algorithm scales linearly with $n$. This algorithm will be the focus of this course.\n",
    "\n",
    "Types of clustering:\n",
    "\n",
    "1. Centroid-based clustering\n",
    "2. Density-based clustering\n",
    "3. Distribution-based clustering\n",
    "4. Hierarchical clustering\n",
    "\n",
    "For an exhaustive list of different approaches to clustering, see _A Comprehensive Survey of Clustering Algorithms Xu, D. & Tian, Y. Ann. Data. Sci. (2015) 2: 165_. Each approach is best suited to a particular data distribution. This course briefly discusses four common approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A popular **clustering** algorithm that groups examples in unsupervised learning. The k-means algorithm basically does the following:\n",
    "\n",
    "Iteratively determines the best k center points (known as **centroids**).\n",
    "Assigns each example to the closest centroid. Those examples nearest the same centroid belong to the same group.\n",
    "The k-means algorithm picks centroid locations to minimize the cumulative square of the distances from each example to its closest centroid.\n",
    "\n",
    "For example, consider the following plot of dog height to dog width:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\">\n",
    "  <img src = \"Images/DogDimensions.svg\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. k-median Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clustering algorithm closely related to **k-means**. The practical difference between the two is as follows:\n",
    "* In k-means, centroids are determined by minimizing the sum of the squares of the distance between a centroid candidate and each of its examples.\n",
    "* In k-median, centroids are determined by minimizing the sum of the distance between a centroid candidate and each of its examples.\n",
    "\n",
    "Note that the definitions of distance are also different:\n",
    "* k-means relies on the Euclidean distance from the centroid to an example. (In two dimensions, the Euclidean distance means using the Pythagorean theorem to calculate the hypotenuse.) For example, the k-means distance between (2,2) and (5,-2) would be:\n",
    "\n",
    "$$\n",
    "Euclidian \\text{ } distance = \\sqrt{(2 - 5)^2 + (2 - -2)^2} = 5\n",
    "$$ (euclidian_distance)\n",
    "\n",
    "* k-median relies on the Manhattan distance from the centroid to an example. This distance is the sum of the absolute deltas in each dimension. For example, the k-median distance between (2,2) and (5,-2) would be:\n",
    "\n",
    "$$\n",
    "Manhattan \\text{ } distance = |2 - 5| + |2 - -2| = 7\n",
    "$$ (euclidian_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.n. Hierarchical Clustering and K-Means Clustering to Identify Subgroups in Surveys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
